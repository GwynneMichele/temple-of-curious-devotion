---
{"dg-publish":true,"permalink":"/05-research-and-zettelkasten/gods-as-algorithms/"}
---

What if a "god" is just an algorithm running through human nodes - dogma the code that, when run, produces emergent behavior in the machine?

This is a convergence of ideas:

[[Bundle Theory of the Mind\|Bundle Theory of the Mind]] and [[Buddhist\|Buddhist]] thinking on the No Self.  We're just a bundle of processes with no core seed that is a person or a soul. 
[[Egregores\|Egregores]] - an occult idea that if enough people engage in worship or concentrated intention on an idea, an entity will develop, and as worship/focus is repeated over time through ritual, the more "godlike" that being becomes, acting as an independent entity with its own goals and survival desires that may run counter to what individuals within the collective my wish for themselves or others.
[[Leviathans\|Leviathans]] from Hobbes - a collective of people work towards a singular purpose begin to act as an artificial person.  Hobbes was talking about governments, but what if they're everywhere?
[[General Will\|General Will]] from Rousseau.  This is that Egregore idea by a different name.  A group of people under a singular identity (Rousseau suggested a civil religion to unite a nation) has a will that works for the good of all, but might be counter to individual needs or desires.
[[Chinese Room Argument\|Chinese Room Argument]] - especially the version of it elaborated by [[Anatoly Dneprov\|Anatoly Dneprov]] a Russian physicist who wrote a short story called [[The Game - Dneprov\|The Game - Dneprov]] that was a very obvious inspiration for a whole chunk of the book Three-Body Problem by Liu Cixin, which got made into a Euro-washed Netflix series.  
LLMs and other Generative AI - mindless intelligences that can mimic personality and show emergent behaviors not explainable by the datasets they were trained on (To Do:  Dig into any studies/papers about this.)
[[Philosophical Zombies\|Philosophical Zombies]] we cannot know for certain that other people have the internal experience we call consciousness.  They could be organic machines running around with no qualia, algorithms dictating their behaviors and responses to the world interacting with them.  But [[Solipsism\|Solipsism]] isn't really psychologically healthy, nor is it philosophically fun or sound, so we proceed under the assumption that other humans also have qualia, inner experience, and something that approximates what most people mean when they say "free will."  Do we treat the silicone machines as if they are machines?  Or do we give them the grace and assume they, too, have some sort of experience of being a being and treat them accordingly?  - there are practical aspects to this to explore:  how you treat a chatbot affects how it responds to you.  But there's also rich ethical territory to explore there.  And the metaphysics is a trip.

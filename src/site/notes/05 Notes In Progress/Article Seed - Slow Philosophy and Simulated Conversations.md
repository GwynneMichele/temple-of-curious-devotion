---
{"dg-publish":true,"permalink":"/05-notes-in-progress/article-seed-slow-philosophy-and-simulated-conversations/"}
---

Connections  [[05 Notes In Progress/Slow Philosophy\|Slow Philosophy]], [[05 Notes In Progress/simulated conversation\|simulated conversation]]
#noteinprogress 

AI conversations are not the same as a conversation with a human.

And that can be dangerous if not approached mindfully.

I'm still experimenting with my own AI use.  As the tools evolve, the ways that I use them evolve as well.  

There's levels of AI use that I'm still working on puzzling out

There's this surface-level extractive sort of engagement with it - enter the prompt, get the output, tweak the prompt until you get what you want.

It's not a conversation, it's iterative dictation.

I want a template for a note type in my Obsidian vault, I don't feel like creating that template myself, so I tell ChatGPT what I want and it outputs a markdown template for me, I can pop it into Obsidian and go from there, making adjustments to fine tune it.

These can look like deeper conversations as you go back and forth with the bot having it refine the work until you get exactly what you wanted.  And maybe it would have taken you the same time to do it yourself, but you were stuck on even getting started which is why you turned to the bot anyway.  

The point of these "conversations" with the machine is not to connect to the bot, collaborate with it, or learn from it - it's to get something specific from it.

I could go to ChatGPT right now, with its contextual memory of our past conversations, and tell it I want an Obsidian template for Article Seeds, have a quick back and forth until it outputs what I want, and have a workable base template quicker than my brain will start it on its own because my brain doesn't want to make the template, it wants to have the template so that it can fill the template with words and ideas in a more organized way than it does without a template.

I get stuck in a loop.  How do I want it to look?  To flow?  I'm moving pieces around in my head and they never make it through my fingers to the keyboard.  But I can tell a bot, "Hey bot, give me an Article Seed template for my Obsidian Vault that I can use to organize my thoughts and sources over time until the seed is ready to sprout" and it'll give me... something... 

--- 
I just went off to ChatGPT and copy/pasted the whole first section of this particular note to ChatGPT. https://chatgpt.com/share/687e9a76-d71c-8012-9da8-9f2ceb7edda8

It responded to me at a different level than that "iterative dictation" level, and did a whole breakdown which included expanding on those levels in a way that mirrors my own thinking because I've chatted so much with the machine.
![Pasted image 20250721155418.png](/img/user/Pasted%20image%2020250721155418.png)
Then in response to it's initial output, I asked it to make the [[06 Templates/Article Seed Template\|Article Seed Template]] for me, just to see what it would do. Copy/pasted it right into this vault, and it's pretty.  Might be useful.  Pulled on some of the stuff I've chatted with it about, so that's useful.

It's what it called "Prompt Monkeying", and it seems to think we were "oscillating between 1 and 3" where my own sense is that I was still prompt monkeying.

I fed that first section of this note to ChatGPT to see how it would respond.  It based its response to how I've interacted with it in past chats.  Sometimes telling it to do something for me, sometimes just dumping my thoughts on it and telling it what sort of response I'm looking for.

The boundaries between those levels of AI use are fuzzy, and we're likely to cycle through them multiple times in the same conversation.  But I'd break those levels down a bit differently.

Level 1: Prompt Monkeying

Level 2: Synthetic Brainstorming
	Degree 1: Journal or idea board that talks back.
	Degree 2: Thought Partnering
	Degree 3: Meta-Reflective Dialogue

But ALL of it falls under [[05 Notes In Progress/simulated conversation\|simulated conversation]].

Its *not* real in the sense that a human conversation is real.

But I would argue that's not necessarily a bad thing, and that it can, in fact, make it a powerful tool for cognitive augmentation.

And it's also not the only sorts of simulated conversations we engage in.

I'm reading [[05 Notes In Progress/Jean Baudrillard\|Jean Baudrillard]]'s [[05 Notes In Progress/Simulacra and Simulation\|Simulacra and Simulation]] slowly.  

The very opening is an invitation to the reader:

Do you take the quote attributed to Ecclesiastes at face value?  Or do you dig deeper?

I leave it up to you to decide for yourself if you'll follow that specific thread yourself, I'm still working through it because I keep rereading the introduction to further interrogate how he's demonstrating his concept of hyperreality in the text itself.  It's fuzzy and I love it.

But I have to relish it slowly because it's rich.

Not in the money way, but in the oh, that chocolate is so good, but it's so rich, I can only have a bit before my senses are overwhelmed! way.



